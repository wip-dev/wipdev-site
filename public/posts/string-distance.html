<!DOCTYPE html><html><head><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/tokyo-night-dark.min.css" rel="stylesheet" /><script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/clojure.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/js.min.js"></script><link href="/styles.css" rel="stylesheet" /></head><body><article><h1>Getting Started with String Distance Metrics</h1><p>I took a little digression from Python and NLTK when I discovered the R package <code>stringdist</code>, which has a collection of functions for string distance calculation and approximate matching based on those metrics. This is one of the main reasons I started learning NLP in the first place, and <code>stringdist</code>, like a lot of R packages, has good documentation including a [paper about the package and underlying metrics](http://www.markvanderloo.eu/files/statistics/loo.pdf). There was no better reason for me to start diving in right away!</p><p>So, here I am sharing some information that I learned.</p><h2>Context</h2><p>If you are typing in a search box, the worst (working) implementation would search for an <i>exact</i> match of what you are typing: the tiniest typo would totally blow your search query. But search implementations should be "smarter" than that: accounting for some margin of error is essential whenever the user input is free text. Part of the solution is attributed to <i>approximate</i> (aka fuzzy) string matching, and this is where a package like <code>stringdist</code> would come in handy.</p><p><strong>Side note:</strong> this is not really cutting edge. Algorithms in this package are a level-up from exact matching, but are still simpler than machine learning models that are used in actual search engines and might include other features to improve search results.</p><h2>Types of distance metrics</h2><p>According to the paper, there are 3 major types of algorithms for calculating distance. I will glance over them in this section.</p><h3>Edit-based distance</h3><p>Algorithms in this category calculate the distance between two strings based on the number of edits of one string that are required to match another string. These edits can be:</p><ul><li>insertions (<code>&quot;fo&quot; -&gt; &quot;for&quot;</code>),</li><li>deletions (<code>&quot;care&quot; -&gt; &quot;car&quot;</code>),</li><li>substitutions (<code>&quot;fuzz&quot; -&gt; &quot;buzz&quot;</code>), or</li><li>transpositions (<code>&quot;pat&quot; -&gt; &quot;apt&quot;</code>).</li></ul><p>The algorithms differ in whether they allow only one, some, or all of these edits. For example, the longest common substring (LCS) method only allows insertions and deletions. They also differ in the range of possible values.</p><pre><code class="r">stringdist&#40;&quot;foo&quot;,  &quot;boo&quot;,   method = &quot;lcs&quot;&#41; # 2
</code></pre><h3>q-gram distance</h3><p>In the context of such algorithms, q-gram is simply a string of length q. So, a q-gram-based method takes its input strings and computes corresponding q-grams. For example, given q = 2, <code>&quot;fizz&quot;</code> would produce 3 q-grams (<code>&quot;fi&quot;</code>, <code>&quot;iz&quot;</code>, and <code>&quot;zz&quot;</code>). The calculations are then performed on these q-gram sets.</p><p>One q-gram-based method is the Jaccard method which calculates the proportion of uncommon q-grams. You could guess that it ranges from 0 to 1.</p><pre><code class="r">stringdist&#40;&quot;leia&quot;, &quot;leela&quot;, method = &quot;jaccard&quot;, q = 2&#41; # 0.8333
</code></pre><h3>Heuristic distance</h3><p>Two methods were mentioned in the paper: the Jaro distance and its extension, the Jaro-Winkler distance. These methods are actually developed to account for typing errors using the logic that typing errors result in character substitutions or transpositions between adjacent characters. The further the matched characters are from each other, the larger the penalty added to the distance metric.</p><p>They range from 0 to 1, where 0 is a perfect match.</p><pre><code class="r">stringdist&#40;&quot;comonality&quot;, &quot;commonality&quot;, method = &quot;jw&quot;&#41; # 0.0303
</code></pre><h2>Application</h2><p>The use of such methods is mainly a <i>lookup</i> function: input string(s) is searched into another set, the dictionary, for matches. A function like <code>stringdist::amatch&#40;&#41;</code> calculates the distance metric of interests and picks up the best match. Also, it is straightforward to write a function that gets the best n matches along with the calculated metric if you wish.</p><p>It is worth noting that different metrics produce different results, and such difference might be huge. So, the choice should be consciously made based on the type of text being analyzed. Also, since they don't have the same ranges of possible values, they are not directly comparable.</p><hr/><p>That sums up what I have learned about string distance and approximate matching from reading the <code>stringdist</code> package paper. From here I will probably get back to progressing in Python and NLTK to continue learning.</p></article><script src="/main.js"></script></body></html>